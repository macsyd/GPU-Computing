{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/macsyd/GPU-Computing/blob/main/csc485b_assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39e4HvsbjPkm"
      },
      "source": [
        "Extra stuff here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dclGnLGAgbtH",
        "outputId": "0ec08828-872b-4088-ca0e-959c68f09a0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-n89ae17k\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-n89ae17k\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 28f872a2f99a1b201bcd0db14fdbc5a496b9bfd7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "The nvcc4jupyter extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc4jupyter\n"
          ]
        }
      ],
      "source": [
        "# Load the extension that allows us to compile CUDA code in python notebooks\n",
        "# Documentation is here: https://nvcc4jupyter.readthedocs.io/en/latest/\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVbDQthwogQF"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save -g \"source\" -n \"data_types.h\"\n",
        "/**\n",
        " * A collection of commonly used data types throughout this project.\n",
        " */\n",
        "#pragma once\n",
        "\n",
        "#include <stdint.h> // uint32_t\n",
        "\n",
        "using element_t = uint32_t;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqET4uI2ggwf"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save -g \"source\" -n \"cuda_common.h\"\n",
        "/**\n",
        " * Standard macros that can be useful for error checking.\n",
        " * https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__ERROR.html\n",
        " */\n",
        "#pragma once\n",
        "\n",
        "#include <cuda.h>\n",
        "\n",
        "#define CUDA_CALL(exp)                                       \\\n",
        "    do {                                                     \\\n",
        "        cudaError res = (exp);                               \\\n",
        "        if(res != cudaSuccess) {                             \\\n",
        "            printf(\"Error at %s:%d\\n %s\\n\",                  \\\n",
        "                __FILE__,__LINE__, cudaGetErrorString(res)); \\\n",
        "           exit(EXIT_FAILURE);                               \\\n",
        "        }                                                    \\\n",
        "    } while(0)\n",
        "\n",
        "#define CHECK_ERROR(msg)                                             \\\n",
        "    do {                                                             \\\n",
        "        cudaError_t err = cudaGetLastError();                        \\\n",
        "        if(cudaSuccess != err) {                                     \\\n",
        "            printf(\"Error (%s) at %s:%d\\n %s\\n\",                     \\\n",
        "                (msg), __FILE__, __LINE__, cudaGetErrorString(err)); \\\n",
        "            exit(EXIT_FAILURE);                                      \\\n",
        "        }                                                            \\\n",
        "    } while (0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GY0L7rKhoVaZ"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save -g \"source\" -n \"data_generator.h\"\n",
        "/**\n",
        " * Functions for generating random input data with a fixed seed\n",
        " */\n",
        "#pragma once\n",
        "\n",
        "#include <random>  // for std::mt19937, std::uniform_int_distribution\n",
        "#include <vector>\n",
        "\n",
        "#include \"data_types.h\"\n",
        "\n",
        "namespace csc485b {\n",
        "namespace a1 {\n",
        "\n",
        "/**\n",
        " * Generates and returns a vector of random uniform data of a given length, n,\n",
        " * for any integral type. Input range will be [0, 2n].\n",
        " */\n",
        "template < typename T >\n",
        "std::vector< T > generate_uniform( std::size_t n )\n",
        "{\n",
        "    // for details of random number generation, see:\n",
        "    // https://en.cppreference.com/w/cpp/numeric/random/uniform_int_distribution\n",
        "    std::size_t random_seed = 20240916;  // use magic seed\n",
        "    std::mt19937 rng( random_seed );     // use mersenne twister generator\n",
        "    std::uniform_int_distribution<> distrib(0, 2 * n);\n",
        "\n",
        "    std::vector< T > random_data( n ); // init array\n",
        "    std::generate( std::begin( random_data )\n",
        "                 , std::end  ( random_data )\n",
        "                 , [ &rng, &distrib ](){ return static_cast< T >( distrib( rng ) ); });\n",
        "\n",
        "    return random_data;\n",
        "}\n",
        "\n",
        "} // namespace a1\n",
        "} // namespace csc485b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJOKRZuCkDh2"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save -g \"source\" -n \"algorithm_choices.h\"\n",
        "#pragma once\n",
        "\n",
        "#include <vector>\n",
        "\n",
        "#include \"data_types.h\"\n",
        "\n",
        "namespace csc485b {\n",
        "namespace a1 {\n",
        "namespace cpu {\n",
        "\n",
        "void run_cpu_baseline( std::vector< element_t > data, std::size_t switch_at, std::size_t n );\n",
        "\n",
        "} // namespace cpu\n",
        "\n",
        "\n",
        "namespace gpu {\n",
        "\n",
        "void run_gpu_soln( std::vector< element_t > data, std::size_t switch_at, std::size_t n );\n",
        "\n",
        "} // namespace gpu\n",
        "} // namespace a1\n",
        "} // namespace csc485b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3lAuiBEhKjc"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save -g \"source\" -n \"cpu_baseline.cu\"\n",
        "/**\n",
        " * CPU methods that the GPU should outperform.\n",
        " */\n",
        "\n",
        "#include \"algorithm_choices.h\"\n",
        "\n",
        "#include <algorithm> // std::sort()\n",
        "#include <chrono>    // for timing\n",
        "#include <iostream>  // std::cout, std::endl\n",
        "\n",
        "namespace csc485b {\n",
        "namespace a1      {\n",
        "namespace cpu     {\n",
        "\n",
        "/**\n",
        " * Simple solution that just sorts the whole array with a built-in sort\n",
        " * function and then resorts the last portion in the opposing order with\n",
        " * a second call to that same built-in sort function.\n",
        " */\n",
        "void opposing_sort( element_t * data, std::size_t invert_at_pos, std::size_t num_elements )\n",
        "{\n",
        "\n",
        "    std::sort( data, data + num_elements, std::less< element_t >{} );\n",
        "    std::sort( data + invert_at_pos, data + num_elements, std::greater< element_t >{} );\n",
        "}\n",
        "\n",
        "/**\n",
        " * Run the single-threaded CPU baseline that students are supposed to outperform\n",
        " * in order to obtain higher grades on this assignment. Times the execution and\n",
        " * prints to the standard output (e.g., the screen) that \"wall time.\" Note that\n",
        " * the functions takes the input by value so as to not perturb the original data\n",
        " * in place.\n",
        " */\n",
        "void run_cpu_baseline( std::vector< element_t > data, std::size_t switch_at, std::size_t n )\n",
        "{\n",
        "    auto const cpu_start = std::chrono::high_resolution_clock::now();\n",
        "    opposing_sort( data.data(), switch_at, n );\n",
        "    auto const cpu_end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    std::cout << \"CPU Baseline time: \"\n",
        "              << std::chrono::duration_cast<std::chrono::nanoseconds>(cpu_end - cpu_start).count()\n",
        "              << \" ns\" << std::endl;\n",
        "\n",
        "    for( auto const x : data ) std::cout << x << \" \"; std::cout << std::endl;\n",
        "}\n",
        "\n",
        "} // namespace cpu\n",
        "} // namespace a1\n",
        "} // namespace csc485b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjTbQ3EO2NwQ"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save -g \"source\" -n \"gpu_solution.cu\"\n",
        "/**\n",
        " * The file in which you will implement your GPU solutions!\n",
        " */\n",
        "\n",
        "#include \"algorithm_choices.h\"\n",
        "\n",
        "#include <chrono>    // for timing\n",
        "#include <iostream>  // std::cout, std::endl\n",
        "\n",
        "#include \"cuda_common.h\"\n",
        "\n",
        "namespace csc485b {\n",
        "namespace a1      {\n",
        "namespace gpu     {\n",
        "\n",
        "/**\n",
        " * The CPU baseline benefits from warm caches because the data was generated on\n",
        " * the CPU. Run the data through the GPU once with some arbitrary logic to\n",
        " * ensure that the GPU cache is warm too and the comparison is more fair.\n",
        " */\n",
        "__global__\n",
        "void warm_the_gpu( element_t * data, std::size_t invert_at_pos, std::size_t num_elements )\n",
        "{\n",
        "    int const th_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // We know this will never be true, because of the data generator logic,\n",
        "    // but I doubt that the compiler will figure it out. Thus every element\n",
        "    // should be read, but none of them should be modified.\n",
        "    if( th_id < num_elements && data[ th_id ] > num_elements * 100 )\n",
        "    {\n",
        "        ++data[ th_id ]; // should not be possible.\n",
        "    }\n",
        "}\n",
        "\n",
        "/**\n",
        " * Your solution. Should match the CPU output.\n",
        " */\n",
        "__global__\n",
        "void opposing_sort( element_t * data, std::size_t invert_at_pos, std::size_t num_elements )\n",
        "{\n",
        "    int const th_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if(th_id < num_elements)\n",
        "    {\n",
        "        // IMPLEMENT ME!\n",
        "\n",
        "        for(int my_lane = th_id; my_lane < num_elements; my_lane += 32) {\n",
        "\n",
        "            for(int macrostep = 2; macrostep <= num_elements; macrostep = macrostep << 1) {\n",
        "\n",
        "                for(int microstep = macrostep >> 1; microstep > 0; microstep = microstep >> 1) {\n",
        "                    int paired_lane = my_lane ^ microstep;\n",
        "                    if (my_lane < paired_lane) {\n",
        "                        if ((((my_lane & macrostep) == 0) && (data[my_lane] > data[paired_lane])) || // first case: data should be sorted in descending order\n",
        "                            (((my_lane & macrostep) != 0) && (data[my_lane] < data[paired_lane]))) { // second case: data should be sorted in ascending order\n",
        "                            //swap elements\n",
        "                            int temp_array_value = data[my_lane];\n",
        "                            data[my_lane] = data[paired_lane];\n",
        "                            data[paired_lane] = temp_array_value;\n",
        "                        }\n",
        "                    }\n",
        "                    __syncthreads();\n",
        "\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        //reverse last 3/4 of array\n",
        "        int three_quarters_threshold = num_elements * 3/4;\n",
        "        if (th_id < 32) {\n",
        "            for(int my_lane = th_id + three_quarters_threshold; my_lane < (three_quarters_threshold + num_elements/8); my_lane += 32) {\n",
        "                int temp_array_value = data[my_lane];\n",
        "                data[my_lane] = data[(num_elements-1) - (my_lane - three_quarters_threshold)];\n",
        "                data[(num_elements-1) - (my_lane - three_quarters_threshold)] = temp_array_value;\n",
        "          }\n",
        "        }\n",
        "\n",
        "        return;\n",
        "    }\n",
        "}\n",
        "\n",
        "/**\n",
        " * Performs all the logic of allocating device vectors and copying host/input\n",
        " * vectors to the device. Times the opposing_sort() kernel with wall time,\n",
        " * but excludes set up and tear down costs such as mallocs, frees, and memcpies.\n",
        " */\n",
        "void run_gpu_soln( std::vector< element_t > data, std::size_t switch_at, std::size_t n )\n",
        "{\n",
        "    // Kernel launch configurations. Feel free to change these.\n",
        "    // This is set to maximise the size of a thread block on a T4, but it hasn't\n",
        "    // been tuned. It's not known if this is optimal.\n",
        "    std::size_t const threads_per_block = 1024;\n",
        "    std::size_t const num_blocks =  1; //( n + threads_per_block - 1 ) / threads_per_block;\n",
        "\n",
        "    // Allocate arrays on the device/GPU\n",
        "    element_t * d_data;\n",
        "    cudaMalloc( (void**) & d_data, sizeof( element_t ) * n );\n",
        "    CHECK_ERROR(\"Allocating input array on device\");\n",
        "\n",
        "    // Copy the input from the host to the device/GPU\n",
        "    cudaMemcpy( d_data, data.data(), sizeof( element_t ) * n, cudaMemcpyHostToDevice );\n",
        "    CHECK_ERROR(\"Copying input array to device\");\n",
        "\n",
        "    // Warm the cache on the GPU for a more fair comparison\n",
        "    warm_the_gpu<<< num_blocks, threads_per_block>>>( d_data, switch_at, n );\n",
        "\n",
        "    // Time the execution of the kernel that you implemented\n",
        "    auto const kernel_start = std::chrono::high_resolution_clock::now();\n",
        "    opposing_sort<<< num_blocks, threads_per_block>>>( d_data, switch_at, n );\n",
        "    auto const kernel_end = std::chrono::high_resolution_clock::now();\n",
        "    CHECK_ERROR(\"Executing kernel on device\");\n",
        "\n",
        "    // After the timer ends, copy the result back, free the device vector,\n",
        "    // and echo out the timings and the results.\n",
        "    cudaMemcpy( data.data(), d_data, sizeof( element_t ) * n, cudaMemcpyDeviceToHost );\n",
        "    CHECK_ERROR(\"Transferring result back to host\");\n",
        "    cudaFree( d_data );\n",
        "    CHECK_ERROR(\"Freeing device memory\");\n",
        "\n",
        "    std::cout << \"GPU Solution time: \"\n",
        "              << std::chrono::duration_cast<std::chrono::nanoseconds>(kernel_end - kernel_start).count()\n",
        "              << \" ns\" << std::endl;\n",
        "\n",
        "    for( auto const x : data ) std::cout << x << \" \"; std::cout << std::endl;\n",
        "}\n",
        "\n",
        "} // namespace gpu\n",
        "} // namespace a1\n",
        "} // namespace csc485b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRvVeK-QifnZ"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save -g \"source\" -n \"main.cu\"\n",
        "/**\n",
        " * Driver for the benchmark comparison. Generates random data,\n",
        " * runs the CPU baseline, and then runs your code.\n",
        " */\n",
        "\n",
        "#include <cstddef>  // std::size_t type\n",
        "#include <iostream> // std::cout, std::endl\n",
        "#include <vector>\n",
        "\n",
        "#include \"algorithm_choices.h\"\n",
        "#include \"data_generator.h\"\n",
        "#include \"data_types.h\"\n",
        "#include \"cuda_common.h\"\n",
        "\n",
        "int main()\n",
        "{\n",
        "    std::size_t const n = 1024;\n",
        "    std::size_t const switch_at = 3 * ( n >> 2 ) ;\n",
        "\n",
        "    auto data = csc485b::a1::generate_uniform< element_t >( n );\n",
        "    csc485b::a1::cpu::run_cpu_baseline( data, switch_at, n );\n",
        "    csc485b::a1::gpu::run_gpu_soln( data, switch_at, n );\n",
        "\n",
        "    return EXIT_SUCCESS;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7F0eVsGjUNp",
        "outputId": "e8e2a0c1-02cb-4afe-9d80-e0dc267f4b85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Baseline time: 44776 ns\n",
            "2 5 6 7 13 19 20 21 21 22 25 30 35 39 40 41 41 41 46 49 49 51 52 52 53 54 54 59 59 65 67 67 68 71 71 74 75 76 80 81 83 83 86 90 99 101 104 104 104 110 110 113 116 117 118 119 120 122 124 131 134 134 141 141 141 144 150 150 152 155 156 164 167 170 172 173 175 176 177 179 181 184 185 186 193 198 199 199 200 201 202 205 205 206 208 210 212 212 213 214 217 217 218 221 221 223 226 228 232 236 238 238 239 241 244 245 246 247 248 254 254 254 256 258 260 260 260 261 266 267 274 274 275 276 279 284 284 285 286 287 287 291 295 297 299 300 303 303 305 306 310 312 315 316 317 321 322 325 326 326 329 333 334 335 339 339 341 345 345 345 349 351 354 358 362 371 374 381 381 384 386 386 386 387 389 391 393 394 394 395 398 401 403 408 410 413 417 419 421 425 428 428 430 430 435 438 440 440 442 443 443 443 444 449 453 454 457 457 460 464 465 467 467 468 471 471 471 473 480 480 480 483 485 486 487 488 497 499 506 508 510 511 512 512 514 521 522 524 525 533 535 541 542 544 548 549 550 552 552 552 555 558 559 559 560 560 563 565 571 573 574 575 575 576 580 580 585 591 591 592 593 595 596 599 601 605 607 608 608 609 609 609 612 613 614 615 616 617 620 621 621 631 632 640 643 654 654 658 660 661 661 662 666 667 667 674 677 678 678 679 679 680 682 686 688 689 693 695 696 698 698 698 698 701 701 702 705 706 707 709 711 713 715 717 719 723 726 728 729 729 730 732 737 742 743 744 750 752 754 757 757 757 758 759 761 763 766 767 768 778 780 784 785 787 790 790 790 791 791 793 794 799 800 804 806 806 810 811 814 815 815 816 818 823 823 827 829 831 834 836 836 844 851 852 853 855 856 856 858 859 860 861 863 865 866 867 868 871 872 875 879 880 881 881 883 883 883 884 897 898 899 901 903 904 904 905 907 908 908 910 912 915 915 921 922 923 924 925 926 928 932 935 935 937 939 939 939 940 942 942 947 951 952 955 955 955 959 964 972 975 977 978 980 981 985 985 987 987 990 992 996 997 997 998 999 1002 1004 1005 1010 1011 1011 1012 1012 1013 1014 1015 1017 1019 1023 1025 1025 1026 1026 1026 1027 1029 1031 1034 1036 1037 1038 1039 1039 1048 1049 1049 1050 1051 1052 1056 1057 1058 1061 1061 1064 1066 1070 1072 1072 1076 1079 1081 1081 1083 1083 1084 1086 1086 1088 1089 1094 1095 1099 1099 1102 1105 1109 1111 1115 1116 1118 1119 1122 1126 1130 1131 1131 1133 1137 1137 1141 1146 1147 1149 1154 1154 1156 1158 1160 1160 1160 1167 1167 1169 1169 1172 1172 1179 1179 1182 1183 1183 1187 1187 1187 1191 1192 1192 1192 1193 1194 1196 1197 1198 1200 1206 1210 1212 1213 1219 1220 1220 1226 1227 1228 1240 1240 1243 1245 1246 1248 1248 1248 1249 1249 1250 1250 1257 1259 1259 1261 1262 1263 1268 1270 1272 1273 1275 1278 1281 1283 1283 1284 1287 1288 1290 1293 1295 1296 1298 1299 1301 1301 1303 1310 1310 1311 1317 1319 1320 1322 1323 1323 1324 1324 1325 1328 1329 1331 1331 1332 1333 1334 1337 1339 1339 1342 1342 1343 1344 1349 1349 1350 1355 1357 1359 1361 1362 1366 1370 1371 1374 1376 1378 1378 1380 1380 1384 1385 1386 1386 1387 1388 1389 1392 1394 1403 1406 1408 1409 1413 1414 1416 1416 1417 1424 1424 1426 1429 1429 1430 1431 1435 1435 1436 1436 1437 1438 1440 1440 1441 1444 1448 1449 1452 1453 1454 1455 1459 1461 1462 1465 1467 1467 1470 1474 1475 1476 1479 1480 1481 1483 1483 1483 1484 1489 1491 1491 1493 1493 1493 1494 1497 1499 1499 1501 1501 1501 1502 1505 1505 1506 1507 1512 1513 1513 1516 1518 2048 2045 2045 2043 2043 2040 2037 2036 2029 2027 2026 2018 2016 2012 2008 2007 2006 2006 2003 2000 1998 1998 1994 1992 1990 1989 1988 1986 1985 1985 1980 1974 1968 1966 1961 1959 1957 1956 1955 1955 1954 1953 1950 1949 1948 1946 1939 1937 1937 1934 1929 1926 1926 1924 1923 1920 1915 1911 1909 1904 1903 1893 1890 1888 1888 1883 1881 1876 1870 1864 1864 1862 1861 1859 1857 1855 1855 1854 1852 1850 1849 1845 1836 1836 1833 1833 1831 1828 1827 1827 1826 1823 1822 1822 1819 1819 1819 1817 1817 1816 1815 1815 1812 1808 1806 1806 1798 1798 1793 1792 1782 1782 1782 1780 1779 1778 1777 1776 1773 1772 1772 1769 1767 1766 1765 1764 1761 1759 1759 1754 1751 1749 1749 1746 1745 1745 1743 1742 1741 1741 1739 1739 1738 1731 1727 1727 1725 1725 1722 1721 1710 1709 1708 1708 1706 1701 1696 1696 1695 1694 1693 1690 1685 1684 1682 1680 1680 1678 1672 1671 1670 1668 1666 1663 1660 1659 1658 1657 1657 1655 1655 1655 1655 1654 1652 1652 1650 1648 1647 1646 1646 1645 1639 1635 1635 1635 1632 1631 1630 1630 1627 1622 1621 1621 1616 1616 1616 1616 1614 1613 1611 1609 1608 1607 1606 1606 1604 1601 1600 1600 1596 1589 1588 1586 1586 1585 1584 1584 1580 1578 1576 1573 1572 1565 1558 1557 1553 1552 1551 1551 1548 1542 1542 1540 1539 1538 1536 1535 1535 1533 1531 1528 1522 1520 1519 1518 \n",
            "GPU Solution time: 13767 ns\n",
            "2 5 6 7 13 19 20 21 21 22 25 30 35 39 40 41 41 41 46 49 49 51 52 52 53 54 54 59 59 65 67 67 68 71 71 74 75 76 80 81 83 83 86 90 99 101 104 104 104 110 110 113 116 117 118 119 120 122 124 131 134 134 141 141 141 144 150 150 152 155 156 164 167 170 172 173 175 176 177 179 181 184 185 186 193 198 199 199 200 201 202 205 205 206 208 210 212 212 213 214 217 217 218 221 221 223 226 228 232 236 238 238 239 241 244 245 246 247 248 254 254 254 256 258 260 260 260 261 266 267 274 274 275 276 279 284 284 285 286 287 287 291 295 297 299 300 303 303 305 306 310 312 315 316 317 321 322 325 326 326 329 333 334 335 339 339 341 345 345 345 349 351 354 358 362 371 374 381 381 384 386 386 386 387 389 391 393 394 394 395 398 401 403 408 410 413 417 419 421 425 428 428 430 430 435 438 440 440 442 443 443 443 444 449 453 454 457 457 460 464 465 467 467 468 471 471 471 473 480 480 480 483 485 486 487 488 497 499 506 508 510 511 512 512 514 521 522 524 525 533 535 541 542 544 548 549 550 552 552 552 555 558 559 559 560 560 563 565 571 573 574 575 575 576 580 580 585 591 591 592 593 595 596 599 601 605 607 608 608 609 609 609 612 613 614 615 616 617 620 621 621 631 632 640 643 654 654 658 660 661 661 662 666 667 667 674 677 678 678 679 679 680 682 686 688 689 693 695 696 698 698 698 698 701 701 702 705 706 707 709 711 713 715 717 719 723 726 728 729 729 730 732 737 742 743 744 750 752 754 757 757 757 758 759 761 763 766 767 768 778 780 784 785 787 790 790 790 791 791 793 794 799 800 804 806 806 810 811 814 815 815 816 818 823 823 827 829 831 834 836 836 844 851 852 853 855 856 856 858 859 860 861 863 865 866 867 868 871 872 875 879 880 881 881 883 883 883 884 897 898 899 901 903 904 904 905 907 908 908 910 912 915 915 921 922 923 924 925 926 928 932 935 935 937 939 939 939 940 942 942 947 951 952 955 955 955 959 964 972 975 977 978 980 981 985 985 987 987 990 992 996 997 997 998 999 1002 1004 1005 1010 1011 1011 1012 1012 1013 1014 1015 1017 1019 1023 1025 1025 1026 1026 1026 1027 1029 1031 1034 1036 1037 1038 1039 1039 1048 1049 1049 1050 1051 1052 1056 1057 1058 1061 1061 1064 1066 1070 1072 1072 1076 1079 1081 1081 1083 1083 1084 1086 1086 1088 1089 1094 1095 1099 1099 1102 1105 1109 1111 1115 1116 1118 1119 1122 1126 1130 1131 1131 1133 1137 1137 1141 1146 1147 1149 1154 1154 1156 1158 1160 1160 1160 1167 1167 1169 1169 1172 1172 1179 1179 1182 1183 1183 1187 1187 1187 1191 1192 1192 1192 1193 1194 1196 1197 1198 1200 1206 1210 1212 1213 1219 1220 1220 1226 1227 1228 1240 1240 1243 1245 1246 1248 1248 1248 1249 1249 1250 1250 1257 1259 1259 1261 1262 1263 1268 1270 1272 1273 1275 1278 1281 1283 1283 1284 1287 1288 1290 1293 1295 1296 1298 1299 1301 1301 1303 1310 1310 1311 1317 1319 1320 1322 1323 1323 1324 1324 1325 1328 1329 1331 1331 1332 1333 1334 1337 1339 1339 1342 1342 1343 1344 1349 1349 1350 1355 1357 1359 1361 1362 1366 1370 1371 1374 1376 1378 1378 1380 1380 1384 1385 1386 1386 1387 1388 1389 1392 1394 1403 1406 1408 1409 1413 1414 1416 1416 1417 1424 1424 1426 1429 1429 1430 1431 1435 1435 1436 1436 1437 1438 1440 1440 1441 1444 1448 1449 1452 1453 1454 1455 1459 1461 1462 1465 1467 1467 1470 1474 1475 1476 1479 1480 1481 1483 1483 1483 1484 1489 1491 1491 1493 1493 1493 1494 1497 1499 1499 1501 1501 1501 1502 1505 1505 1506 1507 1512 1513 1513 1516 1518 2048 2045 2045 2043 2043 2040 2037 2036 2029 2027 2026 2018 2016 2012 2008 2007 2006 2006 2003 2000 1998 1998 1994 1992 1990 1989 1988 1986 1985 1985 1980 1974 1968 1966 1961 1959 1957 1956 1955 1955 1954 1953 1950 1949 1948 1946 1939 1937 1937 1934 1929 1926 1926 1924 1923 1920 1915 1911 1909 1904 1903 1893 1890 1888 1888 1883 1881 1876 1870 1864 1864 1862 1861 1859 1857 1855 1855 1854 1852 1850 1849 1845 1836 1836 1833 1833 1831 1828 1827 1827 1826 1823 1822 1822 1819 1819 1819 1817 1817 1816 1815 1815 1812 1808 1806 1806 1798 1798 1793 1792 1782 1782 1782 1780 1779 1778 1777 1776 1773 1772 1772 1769 1767 1766 1765 1764 1761 1759 1759 1754 1751 1749 1749 1746 1745 1745 1743 1742 1741 1741 1739 1739 1738 1731 1727 1727 1725 1725 1722 1721 1710 1709 1708 1708 1706 1701 1696 1696 1695 1694 1693 1690 1685 1684 1682 1680 1680 1678 1672 1671 1670 1668 1666 1663 1660 1659 1658 1657 1657 1655 1655 1655 1655 1654 1652 1652 1650 1648 1647 1646 1646 1645 1639 1635 1635 1635 1632 1631 1630 1630 1627 1622 1621 1621 1616 1616 1616 1616 1614 1613 1611 1609 1608 1607 1606 1606 1604 1601 1600 1600 1596 1589 1588 1586 1586 1585 1584 1584 1580 1578 1576 1573 1572 1565 1558 1557 1553 1552 1551 1551 1548 1542 1542 1540 1539 1538 1536 1535 1535 1533 1531 1528 1522 1520 1519 1518 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "%cuda_group_run --group \"source\" --compiler-args \"-O3 -g -std=c++20 -arch=sm_75\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0Yqomwu6WsP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}